\section{Near-Threshold Parallel Architectures} \label{sec:clustering}

Deslinkski et al.~\cite{dreslinski2010near} claim ``In applications where there
is an abundance of thread-level parallelism the intention is to use 10 s to 100
s of NTC processor cores that will regain 10-â€“50X of the performance, while
remaining energy efficient.'' In order to regain the performance lost from using
near-threshold techniques, Zhai et al.~\cite{Zhai:2007kn} and Dreslinski et
al.~\cite{Dreslinski:2007id} present a technique for leveraging parallelism in
the NTC regime. The proposed architecture groups multiple slower-cores into
clusters which share a faster L1 cache. The cache operates at $n$ times higher
frequency than the cores, where $n$ is the number of cores in a cluster. This is
motivated by the observation that SRAM has a higher energy optimal $V_{dd}$ and
$V_{th}$ than logic due to its lower activity factor and higher relative
leakage.  As a result of SRAMs higher energy optimal $V_{dd}$, the energy
optimal frequency of memory is higher than that of logic.  Based on this
observation, the proposed technique shares the first-level cache with multiple,
slower cores allowing individual tuning of $V_{dd}$ and $V_{th}$ between the
cores and memory. Using this architecture, the cores still maintain single-cycle
memory accesses while the core and memory can each operate at their energy
optimal $V_{dd}$ and $V_{th}$. Running the memory at a higher $V_{dd}$ also
helps mitigate many of the reliability issues affecting SRAM in the
near-threshold regime.

Using this technique, a 71\% energy savings over a baseline single core machine
on the highly parallel SPLASH2 benchmark is demonstrated. However, investigating
these claims reveals some shortcomings with this approach.  Of primary concern
is the large area overhead required to achieve the same benchmark performance.
In order to achieve the same performance as a single core baseline system on the
\emph{Cholesky} benchmark, 6 cores and 3 times the baseline amount of cache were
required.  In the worst case, some benchmarks require as many as 16 cores and 32
times as much L1 cache (\SI{2}{\mega\byte} vs \SI{64}{\kilo\byte}) to achieve
the same performance as the baseline.  It is important to remember that these
results are being presented in comparison to a single core reference on a highly
parallel workload. By Amdahl's law, the speedup from parallelism will have
diminishing returns as more cores are added.  The corollary is that the biggest
benefit from parallelism will be realized by going from a single core to several
cores. Emphasizing this point, their results show only a an approximate 15\%
energy efficiency improvement when moving from a traditional $V_{dd}$ scaled CMP
to a clustered architecture without $V_{th}$ tuning.

The clustering technique also uses separate $V_{th}$ tuning for the core and
cache to find the energy optimal voltage for the same performance. However, in
examining these voltages actually are, it is revealed that neither $V_{dd}$
of the cache nor the logic is actually in the near-threshold regime as defined
by the paper, and both are in fact operating at a $V_{dd}$ 2x--3x higher than
the selected $V_{th}$. In modern process technologies, the standard $V_{dd}$ is
already approaching 2x $V_{th}$. As described in Section~\ref{sec:bodybiasing},
the techniques for tuning $V_{th}$ are also becoming less effective.

One final concern is that while energy optimal cluster configurations are
presented for each SPLASH2 benchmark, no co-optimized configuration is given.
This could potentially be an issue as the energy optimal range of cores,
clusters, cache sizes, $V_{dd}$ and $V_{th}$ is large. It is unclear what the
energy savings across benchmarks for different configurations will be.
