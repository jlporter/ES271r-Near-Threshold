\section{Conclusion}
\label{sec:conclusion}

In the general-purpose server computing space, near-threshold computing is not a viable solution to achieving more energy efficiency computing while maintaining system throughput.
The inherent problems of slower devices and increased variability in near-threshold computing are still major barriers for a near-threshold server processor to achieve the same throughput level as a super-threshold server processor.
The state-of-the-art device optimization for low voltage operation provides little performance boost to transistors operating in the near-threshold region.
Soft-edge clocking becomes less effective in combating variation in near-threshold.
At the same time body-biasing, which has been a reliable method for variation compensation, is fading away as technology scales.
Adding to the difficulties of applying near-threshold computing, the inefficiency of delivering power to a low voltage chip and the stricter requirement on the power supply diminishes the power reduction benefits from operating the server processor at low voltage.
Worst of all, the marginal parallelism that can be extracted from the already highly parallel server workload is far from enough to bridge the 10X performance gap between near-threshold computing and traditional above threshold computing.
